{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AbhinavKasubojula\\OneDrive - Kenall Inc\\Desktop\\code\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "\n",
    "# Initialize Pinecone\n",
    "\n",
    "\n",
    "# Load embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Doc 2: Green underlined is add-in, Red strike through is deleted This, Distance: 1.4112508296966553, Document: Green underlined is add-in, Red strike through is deleted\n",
      "\n",
      "This notice is posted in its entirety and...\n",
      "Metadata: Doc 4: An official website of the United States government Here’s how, Distance: 1.5179674625396729, Document: An official website of the United States government\n",
      "\n",
      "Here’s how you know\n",
      "\n",
      "fEngnece’) ©W912EP22R0042 ...\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "docs=[]\n",
    "# Load the FAISS index\n",
    "storage_directory = r'C:\\Users\\AbhinavKasubojula\\OneDrive - Kenall Inc\\Desktop\\code\\stored_data'\n",
    "index = faiss.read_index(os.path.join(storage_directory, 'faiss_index.bin'))\n",
    "\n",
    "# Load document texts\n",
    "with open(os.path.join(storage_directory, 'documents.pkl'), 'rb') as f:\n",
    "    documents = pickle.load(f)\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(storage_directory, 'metadata.pkl'), 'rb') as f:\n",
    "    file_metadata = pickle.load(f)\n",
    "\n",
    "# Function to perform a vector query\n",
    "def retrieve_text_and_doc(query, k=2):\n",
    "    # Step 1: Compute the query embedding\n",
    "    query_embedding = embedding_model.encode([query], convert_to_tensor=False)\n",
    "\n",
    "    # Step 2: Perform the search in the FAISS index\n",
    "    distances, indices = index.search(np.array(query_embedding).astype('float32'), k)\n",
    "\n",
    "    # Step 3: Retrieve the corresponding documents and metadata\n",
    "    retrieved_docs = [documents[i] for i in indices[0]]\n",
    "    retrieved_metadata = [file_metadata[i] for i in indices[0]]\n",
    "\n",
    "    return retrieved_docs, retrieved_metadata, distances[0]\n",
    "\n",
    "# Example usage\n",
    "query = input(\"enter query\")\n",
    "retrieved_docs, retrieved_metadata, distances = retrieve_text_and_doc(query)\n",
    "retrieved_text = \" \".join(i for i in retrieved_docs)\n",
    "\n",
    "\n",
    "\n",
    "for doc, meta, dist in zip(retrieved_docs, retrieved_metadata, distances):\n",
    "    print(f\"Metadata: {meta}, Distance: {dist}, Document: {doc[:100]}...\") \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Initialize an empty list to store previous questions and answers\n",
    "memory = []\n",
    "\n",
    "# Pinecone text retrieval part (you've done this)\n",
    "def generate_response(cx, q):\n",
    "    global memory\n",
    "\n",
    "    # Retrieved text as context from Pinecone\n",
    "    retrieved_text = cx\n",
    "\n",
    "    # Prepare the prompt with memory of past interactions\n",
    "    memory_prompt = \"\\n\".join(memory)  # Join the previous interactions\n",
    "    question = q\n",
    "    prompt = f\"Here is some context:\\n{retrieved_text}\\n{memory_prompt}\\n\\nNow, based on this, can you answer the following question: {question}\"\n",
    "\n",
    "    # Ollama API call to generate a response\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"model\": \"llama3.1:latest\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False  # Disable streaming\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    # Check the response from the model\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        ans = result['response']\n",
    "        print(\"Model response:\", ans)\n",
    "\n",
    "        # Store the current question and answer in memory\n",
    "        memory.append(f\"Q: {question}\\nA: {ans}\")\n",
    "        if len(memory) > 5:  \n",
    "            memory = memory[-5:]\n",
    "\n",
    "        return ans\n",
    "    else:\n",
    "        print(\"Error:\", response.text)\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "context = retrieved_text\n",
    "question = query\n",
    "answer = generate_response(context, question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = generate_response(\"did you remember your last 3 responses?\", \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "huggingface_token = \"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\"  \n",
    "\n",
    "torch_dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch_dtype, \"low_cpu_mem_usage\": True},  \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "generation_kwargs = {\n",
    "    \"max_length\": 15000,  \n",
    "    'max_new_tokens': 100,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"truncation\": True \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"Please list all the personnel with Professional Engineer (PE) license\" \n",
    "p = cx + \" \"+ p\n",
    "result = pipeline(p, **generation_kwargs)\n",
    "print(result)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR Processor class\n",
    "class OCRProcessor:\n",
    "    def __init__(self, tesseract_path):\n",
    "        pytesseract.pytesseract.tesseract_cmd = tesseract_path\n",
    "    \n",
    "    def process_pdf(self, pdf_path):\n",
    "        try:\n",
    "            print(f\"Processing PDF for OCR: {pdf_path}\")\n",
    "            pages = convert_from_path(pdf_path, dpi=300)\n",
    "            extracted_text = []\n",
    "            \n",
    "            for page_num, page in enumerate(pages):\n",
    "                text = pytesseract.image_to_string(page, lang='eng')\n",
    "                extracted_text.append(text)\n",
    "            \n",
    "            return '\\n'.join(extracted_text)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing OCR for {pdf_path}: {str(e)}\")\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Monitor class\n",
    "class FileMonitor(FileSystemEventHandler):\n",
    "    def __init__(self, directory_to_watch, callback):\n",
    "        self.directory_to_watch = directory_to_watch\n",
    "        self.callback = callback\n",
    "    \n",
    "    def on_created(self, event):\n",
    "        if event.is_directory or not event.src_path.endswith('.pdf'):\n",
    "            return\n",
    "        \n",
    "        print(f\"New PDF detected: {event.src_path}\")\n",
    "        logging.info(f\"New PDF detected: {event.src_path}\")\n",
    "        try:\n",
    "            self.callback(event.src_path)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {event.src_path}: {str(e)}\")\n",
    "    \n",
    "    def start(self):\n",
    "        observer = Observer()\n",
    "        observer.schedule(self, self.directory_to_watch, recursive=False)\n",
    "        observer.start()\n",
    "        print(f\"Monitoring directory: {self.directory_to_watch}\")\n",
    "        logging.info(f\"Started monitoring directory: {self.directory_to_watch}\")\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                time.sleep(1)\n",
    "        except KeyboardInterrupt:\n",
    "            observer.stop()\n",
    "            logging.info(\"File monitoring stopped.\")\n",
    "        \n",
    "        observer.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process new files and update Pinecone\n",
    "def process_new_file(file_path):\n",
    "    text = ocr_processor.process_pdf(file_path)\n",
    "    if text:\n",
    "        vector = embedding_model.encode([text])[0]\n",
    "        vector_id = os.path.basename(file_path)\n",
    "        inderectory: docs/x.upsert(vectors=[(vector_id, vector)])\n",
    "        print(f\"New file '{file_path}' successfully uploaded to Pinecone.\")\n",
    "\n",
    "# Initialize components\n",
    "tesseract_path = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "ocr_processor = OCRProcessor(tesseract_path)\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Start monitoring\n",
    "directory_to_watch = 'docs/'\n",
    "file_monitor = FileMonitor(directory_to_watch, process_new_file)\n",
    "file_monitor.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
