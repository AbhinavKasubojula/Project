{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AbhinavKasubojula\\OneDrive - Kenall Inc\\Desktop\\code\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import os\n",
    "import uuid\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from unstructured.partition.auto import partition\n",
    "import magic\n",
    "\n",
    "import logging\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_file(file_path):\n",
    "    try:\n",
    "        # Use Unstructured's partition method to handle all supported file types\n",
    "        elements = partition(file_path)\n",
    "        extracted_text = \"\\n\".join([str(element) for element in elements])\n",
    "        return extracted_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_doc(directory):\n",
    "    docs = []\n",
    "    doc_names = []\n",
    "    \n",
    "    try:\n",
    "        for filename in os.listdir(directory):\n",
    "            doc_names.append(filename)\n",
    "            file_path = os.path.join(directory,filename)\n",
    "            \n",
    "            # Just a log for debugging\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            \n",
    "            text = read_file(file_path)\n",
    "            if text:\n",
    "                docs.append(text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing directory {directory}: {e}\")\n",
    "    return docs, doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(documents):\n",
    "    model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "    embeddings = model.encode(documents, convert_to_tensor=False)\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: docs/page_1.pdf\n",
      "Processing file: docs/page_2.pdf\n",
      "Processing file: docs/page_3.pdf\n",
      "Processing file: docs/page_4.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = 'docs/'\n",
    "documents, doc_names = read_doc(directory_path)\n",
    "\n",
    "# Compute embeddings\n",
    "v = compute_embeddings(documents)\n",
    "len(v[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03079841,  0.01256095,  0.00396155, ..., -0.04093738,\n",
       "        -0.01922737,  0.01460585],\n",
       "       [ 0.00672184,  0.00303666, -0.03385414, ..., -0.04045713,\n",
       "        -0.00080454,  0.00728154],\n",
       "       [-0.00998642,  0.0072642 , -0.010931  , ..., -0.04368636,\n",
       "         0.04215321,  0.02219727],\n",
       "       [-0.01511251,  0.01407608, -0.03394361, ..., -0.05967831,\n",
       "        -0.02801795, -0.00423528]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import faiss\n",
    "\n",
    "import pickle\n",
    "\n",
    "# FAISS index initialization\n",
    "index = faiss.IndexFlatL2(384)  # d = 384\n",
    "\n",
    "# Add your vectors to the index\n",
    "index.add(v)  # v contains the document embeddings\n",
    "\n",
    "storage_directory = r'C:\\Users\\AbhinavKasubojula\\OneDrive - Kenall Inc\\Desktop\\code\\stored_data'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(storage_directory):\n",
    "    os.makedirs(storage_directory)\n",
    "\n",
    "file_metadata = [{\"doc_number\": i+1, \"doc_name\": name} for i, name in enumerate(doc_names)]\n",
    "\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, os.path.join(storage_directory, 'faiss_index.bin'))\n",
    "\n",
    "# Save document texts\n",
    "with open(os.path.join(storage_directory, 'documents.pkl'), 'wb') as f:\n",
    "    pickle.dump(documents, f)\n",
    "\n",
    "# Optionally save metadata\n",
    "with open(os.path.join(storage_directory, 'metadata.pkl'), 'wb') as f:\n",
    "    pickle.dump(file_metadata, f)\n",
    "\n",
    "\n",
    "print(\"Metadata saved:\", documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_metadata[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "\n",
    "\n",
    "def update_faiss_index(new_embedding):\n",
    "    global index  # Ensure we're using the global index variable\n",
    "    print(\"Updating FAISS index...\")\n",
    "\n",
    "    # Load existing index if not already loaded\n",
    "    if index is None:\n",
    "        index_path = os.path.join(storage_directory, 'faiss_index.bin')\n",
    "        if os.path.exists(index_path):\n",
    "            index = faiss.read_index(index_path)\n",
    "        else:\n",
    "            # If no index exists, create a new one with the correct dimension\n",
    "            index = faiss.IndexFlatL2(new_embedding.shape[1])  # Assuming new_embedding is a 2D array\n",
    "\n",
    "    # Add the new embedding to the existing index\n",
    "    index.add(np.array([new_embedding]).astype('float32'))  # Wrap in another array to add a single embedding\n",
    "\n",
    "    # Save the updated index\n",
    "    faiss.write_index(index, os.path.join(storage_directory, 'faiss_index.bin'))\n",
    "    print(\"FAISS index updated successfully.\")\n",
    "\n",
    "def process_new_file(file_path):\n",
    "\n",
    "    global documents, file_metadata, v, index, storage_directory\n",
    "\n",
    "    print(f\"Processing the new file: {file_path}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Read the file and extract text\n",
    "    t = read_file(file_path)\n",
    "    documents.append(t)\n",
    "    with open(os.path.join(storage_directory, 'documents.pkl'), 'wb') as f:\n",
    "        pickle.dump(documents, f)\n",
    "\n",
    "    doc_number = f\"Doc {len(documents)}\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_metadata.append(f\"{doc_number}:{file_name}\")\n",
    "    with open(os.path.join(storage_directory, 'metadata.pkl'), 'wb') as f:\n",
    "        pickle.dump(file_metadata, f)\n",
    "\n",
    "    em = compute_embeddings(t)\n",
    "    update_faiss_index(em)\n",
    "\n",
    "class FileEventHandler(FileSystemEventHandler):\n",
    "    def __init__(self, process_function):\n",
    "        super().__init__()\n",
    "        self.process_function = process_function  # Pass in the function you want to run when a file is added\n",
    "\n",
    "    def on_created(self, event):\n",
    "        if not event.is_directory:\n",
    "            print(f\"New file added: {event.src_path}\")\n",
    "            self.process_function(event.src_path)  # Call the provided function\n",
    "\n",
    "def monitor_folder(path, process_function):\n",
    "    print(\"started monitoring...\",path)\n",
    "    event_handler = FileEventHandler(process_function)\n",
    "    observer = Observer()\n",
    "    observer.schedule(event_handler, path, recursive=False)\n",
    "    observer.start()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)  # Keep the script running\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_to_monitor = \"C:\\\\Users\\\\AbhinavKasubojula\\\\OneDrive - Kenall Inc\\\\Desktop\\\\code\\\\docs\"\n",
    "    \n",
    "    # Choose which function you want to execute when a new file is added\n",
    "    monitor_folder(folder_to_monitor, process_new_file)  # This will run the `process_new_file` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\AbhinavKasubojula\\\\OneDrive - Kenall Inc\\\\Desktop\\\\code'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Call the function to display metadata and vectors\u001b[39;00m\n\u001b[0;32m     22\u001b[0m METADATA_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mR\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAbhinavKasubojula\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - Kenall Inc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mprint_metadata_and_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m, in \u001b[0;36mprint_metadata_and_vectors\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_metadata_and_vectors\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Load and print metadata\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(METADATA_PATH):\n\u001b[1;32m----> 4\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMETADATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m             metadata \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\AbhinavKasubojula\\OneDrive - Kenall Inc\\Desktop\\code\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\AbhinavKasubojula\\\\OneDrive - Kenall Inc\\\\Desktop\\\\code'"
     ]
    }
   ],
   "source": [
    "def print_metadata_and_vectors():\n",
    "    # Load and print metadata\n",
    "    if os.path.exists(METADATA_PATH):\n",
    "        with open(METADATA_PATH, 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        print(\"Metadata:\")\n",
    "        for idx, entry in enumerate(metadata, start=1):\n",
    "            print(f\"{idx}. {entry}\")\n",
    "    else:\n",
    "        print(\"No metadata found.\")\n",
    "\n",
    "    # Print vectors stored in the FAISS index\n",
    "    if index.ntotal > 0:\n",
    "        print(\"\\nVectors:\")\n",
    "        for i in range(index.ntotal):\n",
    "            vector = index.reconstruct(i)  # Retrieve vector by index\n",
    "            print(f\"Vector {i}: {vector}\")\n",
    "    else:\n",
    "        print(\"No vectors found in the FAISS index.\")\n",
    "\n",
    "# Call the function to display metadata and vectors\n",
    "METADATA_PATH = R'C:\\Users\\AbhinavKasubojula\\OneDrive - Kenall Inc\\Desktop\\code'\n",
    "print_metadata_and_vectors()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
